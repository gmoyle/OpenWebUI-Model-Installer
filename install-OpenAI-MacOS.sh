#!/bin/bash

set -e

# --- Configuration ---
INSTALL_DIR="$(pwd)"
DEFAULT_OPENWEBUI_DATA=~/openwebui-data
DEFAULT_OLLAMA_DATA=~/ollama-data

# --- Helper Functions ---
function check_docker() {
  if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed."
    echo "Please install Docker Desktop from https://www.docker.com/products/docker-desktop"
    exit 1
  fi
  
  if ! docker info >/dev/null 2>&1; then
    echo "‚ùå Docker is not running."
    echo "Please start Docker Desktop and rerun the script."
    exit 1
  fi
  echo "‚úÖ Docker is running."
}

function check_system_requirements() {
  echo "Checking system requirements..."
  
  # Check available RAM
  TOTAL_RAM_GB=$(( $(sysctl -n hw.memsize) / 1024 / 1024 / 1024 ))
  echo "üíª Available RAM: ${TOTAL_RAM_GB}GB"
  
  # Check available disk space (in GB) - macOS compatible
  AVAILABLE_DISK_GB=$(df -h "$HOME" | awk 'NR==2 {print $4}' | sed 's/[^0-9]*//g')
  if [[ "$AVAILABLE_DISK_GB" =~ ^[0-9]+$ ]]; then
    echo "üíæ Available disk space: ${AVAILABLE_DISK_GB}GB"
    
    if [ "$AVAILABLE_DISK_GB" -lt 50 ]; then
      echo "‚ö†Ô∏è Warning: You have less than 50GB of available disk space."
      echo "   The model download may require significant storage."
      printf "Do you want to continue? (y/N): "
      read continue_choice </dev/tty
      if [[ ! "$continue_choice" =~ ^[Yy]$ ]]; then
        echo "Installation cancelled."
        exit 1
      fi
    fi
  else
    echo "üíæ Available disk space: Unable to determine"
    echo "‚ö†Ô∏è Please ensure you have at least 50GB of free disk space"
  fi
}

function check_ollama() {
  if ! command -v ollama &> /dev/null; then
    echo "‚ùå Ollama is not installed."
    echo "Installing Ollama..."
    if command -v brew &> /dev/null; then
      brew install ollama
    else
      curl -fsSL https://ollama.ai/install.sh | sh
    fi
  fi
  echo "‚úÖ Ollama is available."
}

function prompt_for_paths() {
  printf "Enter path for OpenWebUI data [$DEFAULT_OPENWEBUI_DATA]: "
  read OPENWEBUI_DATA_PATH </dev/tty
  OPENWEBUI_DATA_PATH=${OPENWEBUI_DATA_PATH:-$DEFAULT_OPENWEBUI_DATA}

  printf "Enter path for Ollama data [$DEFAULT_OLLAMA_DATA]: "
  read OLLAMA_DATA_PATH </dev/tty
  OLLAMA_DATA_PATH=${OLLAMA_DATA_PATH:-$DEFAULT_OLLAMA_DATA}

  # Expand tilde
  OPENWEBUI_DATA_PATH=$(eval echo "$OPENWEBUI_DATA_PATH")
  OLLAMA_DATA_PATH=$(eval echo "$OLLAMA_DATA_PATH")
}

# --- Main Script ---
echo "üöÄ OpenAI Model Installer for macOS"
echo "=====================================\n"

check_system_requirements
check_docker
check_ollama

echo ""
echo "Select an OpenAI model to install:"
echo "1) gpt-oss-20b  - Optimized for personal computers (~24GB+ RAM recommended)"
echo "2) gpt-oss-120b - Requires a dedicated GPU (~48GB+ VRAM recommended)"
echo ""
printf "Your choice [1-2]: "
read model_choice </dev/tty

case $model_choice in
    1)
        MODEL="gpt-oss-20b"
        MODEL_REPO="openai/gpt-oss-20b"
        RAM_REQUIREMENT="24GB+ RAM"
        ;;
    2)
        MODEL="gpt-oss-120b"
        MODEL_REPO="openai/gpt-oss-120b"
        RAM_REQUIREMENT="48GB+ VRAM (dedicated GPU)"
        ;;
    *)
        echo "Invalid choice. Exiting."
        exit 1
        ;;
esac

echo "You selected: $MODEL"
echo ""

prompt_for_paths

echo ""
echo "Creating data directories..."
mkdir -p "$OPENWEBUI_DATA_PATH"
mkdir -p "$OLLAMA_DATA_PATH"

echo ""
echo "Pulling Docker images..."
docker pull ollama/ollama
docker pull ghcr.io/open-webui/open-webui:main

echo ""
echo "Starting Ollama container..."
# Remove existing container if it exists
docker rm -f ollama 2>/dev/null || true

docker run -d \
  --name ollama \
  --restart unless-stopped \
  -v "$OLLAMA_DATA_PATH:/root/.ollama" \
  -p 11434:11434 \
  --network bridge \
  ollama/ollama

# Wait for Ollama to be ready
echo "Waiting for Ollama to start..."
sleep 10

echo ""
echo "Attempting to pull the model from Hugging Face via Ollama..."
if ollama pull "$MODEL_REPO"; then
  echo "‚úÖ Model '$MODEL' pulled successfully."
else
  echo "‚ùå Failed to pull the model."
  echo "Please ensure you have enough disk space and that the model repository '$MODEL_REPO' is correct."
  exit 1
fi
echo ""
echo "Starting Open WebUI container..."
# Remove existing container if it exists
docker rm -f openwebui 2>/dev/null || true

docker run -d \
  --name openwebui \
  --restart unless-stopped \
  -v "$OPENWEBUI_DATA_PATH:/app/backend/data" \
  -e "OLLAMA_API_BASE_URL=http://localhost:11434" \
  -p 3000:3000 \
  --network bridge \
  ghcr.io/open-webui/open-webui:main

echo ""
echo "üéâ Setup complete!"
echo "=================="
echo ""
echo "‚úÖ Model: $MODEL ($RAM_REQUIREMENT)"
echo "‚úÖ OpenWebUI: http://localhost:3000"
echo "‚úÖ Ollama API: http://localhost:11434"
echo ""
echo "üìã Next steps:"
echo "1. Open your web browser and go to http://localhost:3000"
echo "2. Create an account or sign in"
echo "3. Start chatting with your $MODEL model!"
echo ""
echo "üí° Tip: The first response may take a moment as the model loads into memory."
echo ""
echo "üõ†Ô∏è  To stop the services:"
echo "   docker stop ollama openwebui"
echo ""
echo "üîÑ To restart the services:"
echo "   docker start ollama openwebui"

